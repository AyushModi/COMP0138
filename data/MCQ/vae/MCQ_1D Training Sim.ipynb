{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPkHS2zYxxL4qZ6+jW4qJt1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"918f451f4e284f34a7c0389eff848ba9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ee931e68dad40dca325201f215dbddb","IPY_MODEL_3d3ebc25fccb4929ac1bb3ffa38ad32f","IPY_MODEL_77222952400a41a692df2793facd3d45"],"layout":"IPY_MODEL_9b3f851bfc1746ac892b4c9b7431564c"}},"8ee931e68dad40dca325201f215dbddb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fafbf663b994c89a5a1453df6a58c9a","placeholder":"​","style":"IPY_MODEL_d69164103fe34a719ceb65e9fd37a627","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"3d3ebc25fccb4929ac1bb3ffa38ad32f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7871bf7125c4fff86fdc2cd277813cf","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db9c6531fc1a42a98478e42976f932ba","value":231508}},"77222952400a41a692df2793facd3d45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_024ecb34e1f64d1db6be6ab6e0230b25","placeholder":"​","style":"IPY_MODEL_94f48f4dade6418695ba87558850914b","value":" 232k/232k [00:00&lt;00:00, 1.95MB/s]"}},"9b3f851bfc1746ac892b4c9b7431564c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fafbf663b994c89a5a1453df6a58c9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d69164103fe34a719ceb65e9fd37a627":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7871bf7125c4fff86fdc2cd277813cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db9c6531fc1a42a98478e42976f932ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"024ecb34e1f64d1db6be6ab6e0230b25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94f48f4dade6418695ba87558850914b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92f917ef9d85452daf5197e2b011012b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cff330c7a96b4d339cb27bbbec9a766c","IPY_MODEL_ed61d11e252f458a9237e8c65261e040","IPY_MODEL_8d895146260540bdb137bf4ee89f582d"],"layout":"IPY_MODEL_c73d0068711543a6a5a88c52e292b512"}},"cff330c7a96b4d339cb27bbbec9a766c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6c00cd6f90847e3a7cb5a0a8b29b54d","placeholder":"​","style":"IPY_MODEL_a109e150cb3e4c49a8c2c60aaf4d5689","value":"Downloading (…)okenizer_config.json: 100%"}},"ed61d11e252f458a9237e8c65261e040":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc6a3e12cfdf4fe4927cdd10ec33fdc7","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7975e3420e874a3caf68fadf6ab2b6bf","value":28}},"8d895146260540bdb137bf4ee89f582d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e614b36f5a004cf4b3c0baa48098f62e","placeholder":"​","style":"IPY_MODEL_750aadf7f41344d2bcf29c215ad95cb7","value":" 28.0/28.0 [00:00&lt;00:00, 1.06kB/s]"}},"c73d0068711543a6a5a88c52e292b512":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6c00cd6f90847e3a7cb5a0a8b29b54d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a109e150cb3e4c49a8c2c60aaf4d5689":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc6a3e12cfdf4fe4927cdd10ec33fdc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7975e3420e874a3caf68fadf6ab2b6bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e614b36f5a004cf4b3c0baa48098f62e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"750aadf7f41344d2bcf29c215ad95cb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"847c6812d70047988d8facc22837e388":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfce2864f68a430fbbe4bba04d9c4650","IPY_MODEL_9e996951caf046f890b32a2a51dc78b4","IPY_MODEL_6dbbd329826a4c818d78f0a6b31ee97e"],"layout":"IPY_MODEL_e1b5e507eee54bcd9eb01c0130048b19"}},"bfce2864f68a430fbbe4bba04d9c4650":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5accf24e681d4762b07a31c63d89d503","placeholder":"​","style":"IPY_MODEL_5420ddea4ed74a20b67905593b63eddc","value":"Downloading (…)lve/main/config.json: 100%"}},"9e996951caf046f890b32a2a51dc78b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e134ed63a0b44968869af56741872cf8","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_976f8ef6a1f946d6a7972cb45e74120e","value":570}},"6dbbd329826a4c818d78f0a6b31ee97e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afe66292dccd4c4492fe664abaa4d56b","placeholder":"​","style":"IPY_MODEL_693af35548db4a90a6c94ba729b1b007","value":" 570/570 [00:00&lt;00:00, 30.4kB/s]"}},"e1b5e507eee54bcd9eb01c0130048b19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5accf24e681d4762b07a31c63d89d503":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5420ddea4ed74a20b67905593b63eddc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e134ed63a0b44968869af56741872cf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"976f8ef6a1f946d6a7972cb45e74120e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"afe66292dccd4c4492fe664abaa4d56b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"693af35548db4a90a6c94ba729b1b007":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37ff2b3b8aa94f4b8f6bc56a8e038b99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b18c0895ac25440a942a06848998c46a","IPY_MODEL_b02d68e763644e29a92894f71a09a6fd","IPY_MODEL_607677972dd74e7f8e1715c8cf1d799f"],"layout":"IPY_MODEL_fcef6eaac46a474eaad9ea000ff766f6"}},"b18c0895ac25440a942a06848998c46a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_931cf896806943f3a30253412b913758","placeholder":"​","style":"IPY_MODEL_b29e993237fb4689844e417c4f10f433","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"b02d68e763644e29a92894f71a09a6fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_976ec337bfde48c88b81012323f41bce","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eaff55b4f17347caa12e0796e87f8b29","value":440473133}},"607677972dd74e7f8e1715c8cf1d799f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9c6a15acfa44543af652cd4dff2c42b","placeholder":"​","style":"IPY_MODEL_4fbeb7ad518a409a93b2e4db1bf77233","value":" 440M/440M [00:02&lt;00:00, 195MB/s]"}},"fcef6eaac46a474eaad9ea000ff766f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"931cf896806943f3a30253412b913758":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b29e993237fb4689844e417c4f10f433":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"976ec337bfde48c88b81012323f41bce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaff55b4f17347caa12e0796e87f8b29":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9c6a15acfa44543af652cd4dff2c42b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fbeb7ad518a409a93b2e4db1bf77233":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UAn4Kzp2hTte","executionInfo":{"status":"ok","timestamp":1676467658272,"user_tz":0,"elapsed":20425,"user":{"displayName":"Ayush Modi","userId":"15866713891896926467"}},"outputId":"084d9b35-ead1-4cc2-a00f-0908867490ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# !cp \"drive/MyDrive/Question Generation/vae/models.py\" .\n","%cd '/content/drive/MyDrive/Second/MCQ/vae/'\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rRFWmg6hg76","executionInfo":{"status":"ok","timestamp":1676467658752,"user_tz":0,"elapsed":484,"user":{"displayName":"Ayush Modi","userId":"15866713891896926467"}},"outputId":"a4600820-06af-4fe4-fe06-fce985d48f3d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Second/MCQ/vae\n","/content/drive/MyDrive/Second/MCQ/vae\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install json-lines\n","## scatter 1.12+cu113\n","# !pip install torch-scatter -f https://data.pyg.org/whl/torch-1.12.1+cu113.html\n","# scatter 1.13+cu116\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n","!pip install import-ipynb\n","import import_ipynb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b5kjClyhs5M","executionInfo":{"status":"ok","timestamp":1676467683167,"user_tz":0,"elapsed":24418,"user":{"displayName":"Ayush Modi","userId":"15866713891896926467"}},"outputId":"fec9b38c-4fad-468f-fb57-8a2dda21cdb1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting json-lines\n","  Downloading json_lines-0.5.0-py2.py3-none-any.whl (6.8 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from json-lines) (1.15.0)\n","Installing collected packages: json-lines\n","Successfully installed json-lines-0.5.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.0+pt113cu116\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting import-ipynb\n","  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from import-ipynb) (5.7.3)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from import-ipynb) (7.9.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (2.0.10)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (57.4.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (0.2.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (4.4.2)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (5.7.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (4.3.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (2.16.2)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (5.2.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->import-ipynb) (0.8.3)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.19.3)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.10.2)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.2.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (0.2.6)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->import-ipynb) (3.0.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.12.1)\n","Installing collected packages: jedi, import-ipynb\n","Successfully installed import-ipynb-0.1.4 jedi-0.18.2\n"]}]},{"cell_type":"code","source":["import argparse\n","import os\n","import random\n","\n","import numpy as np\n","import torch\n","from tqdm.notebook import tqdm, trange\n","from transformers import BertTokenizer\n","\n","from eval2 import eval_vae\n","from utils2 import batch_to_device, get_harv_data_loader, get_squad_data_loader"],"metadata":{"id":"MxjoxzZdlBZw","executionInfo":{"status":"ok","timestamp":1676467694815,"user_tz":0,"elapsed":11654,"user":{"displayName":"Ayush Modi","userId":"15866713891896926467"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from torch_scatter import scatter_max\n","from transformers import BertModel, BertTokenizer\n","\n","def return_mask_lengths(ids):\n","    mask = torch.sign(ids).float()\n","    lengths = torch.sum(mask, 1)\n","    return mask, lengths\n","\n","\n","def cal_attn(query, memories, mask):\n","    ## memories is c_hs, the per-state output\n","    \n","    ## mask is 0 at the paddings\n","    ## line below sets padding to -10000\n","    # mask=1-mask; mask[mask==1] = -float(\"inf\")\n","    mask = (1.0 - mask.float()) * -10000.0\n","    attn_logits = torch.matmul(query, memories.transpose(-1, -2).contiguous())\n","    attn_logits = attn_logits + mask\n","    ## padding goes to 0, because we do softmax of -10000,\n","    attn_weights = F.softmax(attn_logits, dim=-1)\n","    attn_outputs = torch.matmul(attn_weights, memories)\n","    return attn_outputs, attn_logits\n","\n","\n","def gumbel_softmax(logits, tau=1, hard=False, eps=1e-20, dim=-1):\n","    # type: (Tensor, float, bool, float, int) -> Tensor\n","\n","    gumbels = -(torch.empty_like(logits).exponential_() +\n","                eps).log()  # ~Gumbel(0,1)\n","    gumbels = (logits + gumbels) / tau  # ~Gumbel(logits,tau)\n","    y_soft = gumbels.softmax(dim)\n","\n","    if hard:\n","        # Straight through.\n","        index = y_soft.max(dim, keepdim=True)[1]\n","        y_hard = torch.zeros_like(logits).scatter_(dim, index, 1.0)\n","        ret = y_hard - y_soft.detach() + y_soft\n","    else:\n","        # Re-parametrization trick.\n","        ret = y_soft\n","    return ret\n","\n","\n","class CategoricalKLLoss(nn.Module):\n","    def __init__(self):\n","        super(CategoricalKLLoss, self).__init__()\n","\n","    def forward(self, P, Q):\n","        log_P = P.log()\n","        log_Q = Q.log()\n","        kl = (P * (log_P - log_Q)).sum(dim=-1).sum(dim=-1)\n","        return kl.mean(dim=0)\n","\n","\n","class GaussianKLLoss(nn.Module):\n","    def __init__(self):\n","        super(GaussianKLLoss, self).__init__()\n","\n","    def forward(self, mu1, logvar1, mu2, logvar2):\n","        numerator = logvar1.exp() + torch.pow(mu1 - mu2, 2)\n","        fraction = torch.div(numerator, (logvar2.exp()))\n","        kl = 0.5 * torch.sum(logvar2 - logvar1 + fraction - 1, dim=1)\n","        return kl.mean(dim=0)\n","\n","\n","class Embedding(nn.Module):\n","    def __init__(self, bert_model):\n","        super(Embedding, self).__init__()\n","        bert_embeddings = BertModel.from_pretrained(bert_model).embeddings\n","        self.word_embeddings = bert_embeddings.word_embeddings\n","        self.token_type_embeddings = bert_embeddings.token_type_embeddings\n","        self.position_embeddings = bert_embeddings.position_embeddings\n","        self.LayerNorm = bert_embeddings.LayerNorm\n","        self.dropout = bert_embeddings.dropout\n","\n","    def forward(self, input_ids, token_type_ids=None, position_ids=None):\n","        if token_type_ids is None:\n","            token_type_ids = torch.zeros_like(input_ids)\n","        if position_ids is None:\n","            seq_length = input_ids.size(1)\n","            position_ids = torch.arange(\n","                seq_length, dtype=torch.long, device=input_ids.device)\n","            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n","\n","        words_embeddings = self.word_embeddings(input_ids)\n","        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n","        position_embeddings = self.position_embeddings(position_ids)\n","\n","        embeddings = words_embeddings + token_type_embeddings + position_embeddings\n","        embeddings = self.LayerNorm(embeddings)\n","        embeddings = self.dropout(embeddings)\n","\n","        return embeddings\n","\n","\n","class ContextualizedEmbedding(nn.Module):\n","    def __init__(self, bert_model):\n","        super(ContextualizedEmbedding, self).__init__()\n","        bert = BertModel.from_pretrained(bert_model)\n","        self.embedding = bert.embeddings\n","        self.encoder = bert.encoder\n","        self.num_hidden_layers = bert.config.num_hidden_layers\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids=None):\n","        if token_type_ids is None:\n","            token_type_ids = torch.zeros_like(input_ids)\n","\n","        seq_length = input_ids.size(1)\n","        position_ids = torch.arange(\n","            seq_length, dtype=torch.long, device=input_ids.device)\n","        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n","\n","        extended_attention_mask = attention_mask.unsqueeze(\n","            1).unsqueeze(2).float()\n","        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n","        head_mask = [None] * self.num_hidden_layers\n","\n","        embedding_output = self.embedding(\n","            input_ids, position_ids=position_ids, token_type_ids=token_type_ids)\n","        encoder_outputs = self.encoder(embedding_output,\n","                                       extended_attention_mask,\n","                                       head_mask=head_mask)\n","        sequence_output = encoder_outputs[0]\n","\n","        return sequence_output\n","\n","\n","class CustomLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, dropout, bidirectional=False):\n","        super(CustomLSTM, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.bidirectional = bidirectional\n","        self.dropout = nn.Dropout(dropout)\n","        if dropout > 0.0 and num_layers == 1:\n","            dropout = 0.0\n","\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n","                            num_layers=num_layers, dropout=dropout,\n","                            bidirectional=bidirectional, batch_first=True)\n","\n","    def forward(self, inputs, input_lengths, state=None):\n","        _, total_length, _ = inputs.size()\n","\n","        input_packed = pack_padded_sequence(inputs, input_lengths.cpu(),\n","                                            batch_first=True, enforce_sorted=False)\n","\n","        self.lstm.flatten_parameters()\n","        output_packed, state = self.lstm(input_packed, state)\n","\n","        output = pad_packed_sequence(\n","            output_packed, batch_first=True, total_length=total_length)[0]\n","        output = self.dropout(output)\n","\n","        return output, state\n","\n","class PosteriorEncoder(nn.Module):\n","    def __init__(self, embedding, emsize,\n","                 nhidden, nlayers,\n","                 nzqdim, nza, nzadim,nzddim,\n","                 dropout=0.0):\n","        super(PosteriorEncoder, self).__init__()\n","\n","        self.embedding = embedding\n","        self.nhidden = nhidden\n","        self.nlayers = nlayers\n","        self.nzqdim = nzqdim\n","        self.nzddim = nzddim\n","        self.nza = nza\n","        self.nzadim = nzadim\n","\n","        self.encoder = CustomLSTM(input_size=emsize,\n","                                  hidden_size=nhidden,\n","                                  num_layers=nlayers,\n","                                  dropout=dropout,\n","                                  bidirectional=True)\n","\n","        \n","\n","        self.question_attention = nn.Linear(2 * nhidden, 2 * nhidden)\n","        self.context_attention = nn.Linear(2 * nhidden, 2 * nhidden)\n","        self.distractor_attention = nn.Linear(2 * nhidden, 2 * nhidden)\n","        self.zq_attention = nn.Linear(nzddim, 2 * nhidden)\n","\n","        self.zq_linear = nn.Linear(4 * 2 * nhidden, 2 * nzqdim)\n","        self.zd_linear = nn.Linear(nzqdim + 5 * 2 * nhidden, 2 * nzddim)\n","        self.za_linear = nn.Linear(nzqdim + 2 * 2 * nhidden, nza * nzadim)\n","\n","    def forward(self, c_ids, q_ids, a_ids, d_ids):\n","        c_mask, c_lengths = return_mask_lengths(c_ids)\n","        q_mask, q_lengths = return_mask_lengths(q_ids)\n","        d_mask, d_lengths = return_mask_lengths(d_ids)\n","\n","        # question enc\n","        q_embeddings = self.embedding(q_ids)\n","        q_hs, q_state = self.encoder(q_embeddings, q_lengths)\n","        q_h = q_state[0].view(self.nlayers, 2, -1, self.nhidden)[-1]\n","        q_h = q_h.transpose(0, 1).contiguous().view(-1, 2 * self.nhidden)\n","        \n","        ## distractor enc \n","        d_embeddings = self.embedding(d_ids)\n","        d_hs, d_state = self.encoder(d_embeddings, d_lengths)\n","        d_h = d_state[0].view(self.nlayers, 2, -1, self.nhidden)[-1]\n","        d_h = d_h.transpose(0, 1).contiguous().view(-1, 2 * self.nhidden)\n","        ##\n","        # context enc\n","        c_embeddings = self.embedding(c_ids)\n","        c_hs, c_state = self.encoder(c_embeddings, c_lengths)\n","        c_h = c_state[0].view(self.nlayers, 2, -1, self.nhidden)[-1]\n","        c_h = c_h.transpose(0, 1).contiguous().view(-1, 2 * self.nhidden)\n","\n","        # print(f\"q_hs shape: {q_hs.shape}\")\n","        # print(f\"d_hs shape: {d_hs.shape}\")\n","        # print(f\"c_hs shape: {c_hs.shape}\")\n","        # context and answer enc\n","        c_a_embeddings = self.embedding(c_ids, a_ids, None)\n","        c_a_hs, c_a_state = self.encoder(c_a_embeddings, c_lengths)\n","        c_a_h = c_a_state[0].view(self.nlayers, 2, -1, self.nhidden)[-1]\n","        c_a_h = c_a_h.transpose(0, 1).contiguous().view(-1, 2 * self.nhidden)\n","\n","        \n","        # ## context and distractor enc\n","        # c_d_embeddings = self.embedding(c_ids, d_ids, None)\n","        # c_d_hs, c_d_state = self.encoder(c_d_embeddings, c_lengths)\n","        # c_d_h = c_d_state[0].view(self.nlayers, 2, -1, self.nhidden)[-1]\n","        # c_d_h = c_d_h.transpose(0, 1).contiguous().view(-1, 2 * self.nhidden)\n","        # ##\n","\n","        # attetion q, c\n","        mask = c_mask.unsqueeze(1)\n","        c_attned_by_q, _ = cal_attn(self.question_attention(q_h).unsqueeze(1),\n","                                    c_hs,\n","                                    mask)\n","        c_attned_by_q = c_attned_by_q.squeeze(1)\n","\n","        # attetion c, q\n","        mask = q_mask.unsqueeze(1)\n","        q_attned_by_c, _ = cal_attn(self.context_attention(c_h).unsqueeze(1),\n","                                    q_hs,\n","                                    mask)\n","        q_attned_by_c = q_attned_by_c.squeeze(1)\n","\n","        h = torch.cat([q_h, q_attned_by_c, c_h, c_attned_by_q], dim=-1)\n","\n","        zq_mu, zq_logvar = torch.split(self.zq_linear(h), self.nzqdim, dim=1)\n","        zq = zq_mu + torch.randn_like(zq_mu) * torch.exp(0.5 * zq_logvar)\n","\n","        ## attention d, c\n","        mask = c_mask.unsqueeze(1)\n","        c_attned_by_d, _ = cal_attn(self.distractor_attention(d_h).unsqueeze(1),\n","                                       c_hs,\n","                                       mask)\n","        c_attned_by_d = c_attned_by_d.squeeze(1)\n","        ## attetion c, d\n","        mask = d_mask.unsqueeze(1)\n","        d_attned_by_c, _ = cal_attn(self.context_attention(c_h).unsqueeze(1),\n","                                    d_hs,\n","                                    mask)\n","        d_attned_by_c = d_attned_by_c.squeeze(1)\n","\n","        ## attention zq, c\n","        mask = c_mask.unsqueeze(1)\n","        c_attned_by_zq, _ = cal_attn(self.zq_attention(zq).unsqueeze(1),\n","                                       c_hs,\n","                                       mask)\n","        c_attned_by_zq = c_attned_by_zq.squeeze(1)\n","\n","        h = torch.cat([d_h, d_attned_by_c,c_h, c_attned_by_d,zq,c_attned_by_zq], dim=-1)\n","\n","        zd_mu, zd_logvar = torch.split(self.zd_linear(h), self.nzddim, dim=1)\n","        zd = zd_mu + torch.randn_like(zd_mu) * torch.exp(0.5 * zd_logvar)\n","        ##\n","\n","        # attention zq, c_a\n","        mask = c_mask.unsqueeze(1)\n","        c_a_attned_by_zq, _ = cal_attn(self.zq_attention(zq).unsqueeze(1),\n","                                       c_a_hs,\n","                                       mask)\n","        c_a_attned_by_zq = c_a_attned_by_zq.squeeze(1)\n","\n","        h = torch.cat([zq, c_a_attned_by_zq, c_a_h], dim=-1)\n","\n","        za_logits = self.za_linear(h).view(-1, self.nza, self.nzadim)\n","        za_prob = F.softmax(za_logits, dim=-1)\n","        za = gumbel_softmax(za_logits, hard=True)\n","\n","        return zq_mu, zq_logvar, zq, za_prob, za, zd_mu, zd_logvar, zd\n","\n","class PriorEncoder(nn.Module):\n","    def __init__(self, embedding, emsize,\n","                 nhidden, nlayers,\n","                 nzqdim, nza, nzadim,nzddim,\n","                 dropout=0):\n","        super(PriorEncoder, self).__init__()\n","\n","        self.embedding = embedding\n","        self.nhidden = nhidden\n","        self.nlayers = nlayers\n","        self.nzqdim = nzqdim\n","        self.nzddim = nzddim\n","        self.nza = nza\n","        self.nzadim = nzadim\n","\n","        self.context_encoder = CustomLSTM(input_size=emsize,\n","                                          hidden_size=nhidden,\n","                                          num_layers=nlayers,\n","                                          dropout=dropout,\n","                                          bidirectional=True)\n","\n","        self.zq_attention = nn.Linear(nzqdim, 2 * nhidden)\n","\n","        self.zq_linear = nn.Linear(2 * nhidden, 2 * nzqdim)\n","        self.zd_linear = nn.Linear(nzqdim + 2 * 2 * nhidden, 2 * nzddim)\n","        self.za_linear = nn.Linear(nzqdim + 2 * 2 * nhidden, nza * nzadim)\n","\n","    def forward(self, c_ids):\n","        c_mask, c_lengths = return_mask_lengths(c_ids)\n","\n","        c_embeddings = self.embedding(c_ids)\n","        c_hs, c_state = self.context_encoder(c_embeddings, c_lengths)\n","        c_h = c_state[0].view(self.nlayers, 2, -1, self.nhidden)[-1]\n","        c_h = c_h.transpose(0, 1).contiguous().view(-1, 2 * self.nhidden)\n","\n","        zq_mu, zq_logvar = torch.split(self.zq_linear(c_h), self.nzqdim, dim=1)\n","        zq = zq_mu + torch.randn_like(zq_mu)*torch.exp(0.5*zq_logvar)\n","\n","        mask = c_mask.unsqueeze(1)\n","        c_attned_by_zq, _ = cal_attn(self.zq_attention(zq).unsqueeze(1),\n","                                     c_hs,\n","                                     mask)\n","        c_attned_by_zq = c_attned_by_zq.squeeze(1)\n","\n","        h = torch.cat([zq, c_attned_by_zq, c_h], dim=-1)\n","\n","        zd_mu, zd_logvar = torch.split(self.zd_linear(h), self.nzddim, dim=1)\n","        zd = zd_mu + torch.randn_like(zd_mu)*torch.exp(0.5*zd_logvar)\n","\n","        za_logits = self.za_linear(h).view(-1, self.nza, self.nzadim)\n","        za_prob = F.softmax(za_logits, dim=-1)\n","        za = gumbel_softmax(za_logits, hard=True)\n","\n","        return zq_mu, zq_logvar, zq, za_prob, za,zd_mu, zd_logvar, zd\n","\n","    def interpolation(self, c_ids, zq):\n","\n","        c_mask, c_lengths = return_mask_lengths(c_ids)\n","\n","        c_embeddings = self.embedding(c_ids)\n","        c_hs, c_state = self.context_encoder(c_embeddings, c_lengths)\n","        c_h = c_state[0].view(self.nlayers, 2, -1, self.nhidden)[-1]\n","        c_h = c_h.transpose(0, 1).contiguous().view(-1, 2 * self.nhidden)\n","\n","        mask = c_mask.unsqueeze(1)\n","        c_attned_by_zq, _ = cal_attn(\n","            self.zq_attention(zq).unsqueeze(1), c_hs, mask)\n","        c_attned_by_zq = c_attned_by_zq.squeeze(1)\n","\n","        h = torch.cat([zq, c_attned_by_zq, c_h], dim=-1)\n","\n","        za_logits = self.za_linear(h).view(-1, self.nza, self.nzadim)\n","        za = gumbel_softmax(za_logits, hard=True)\n","\n","        return za\n","\n","class AnswerDecoder(nn.Module):\n","    def __init__(self, embedding, emsize,\n","                 nhidden, nlayers,\n","                 dropout=0.0):\n","        super(AnswerDecoder, self).__init__()\n","\n","        self.embedding = embedding\n","\n","        self.context_lstm = CustomLSTM(input_size=4 * emsize,\n","                                       hidden_size=nhidden,\n","                                       num_layers=nlayers,\n","                                       dropout=dropout,\n","                                       bidirectional=True)\n","\n","        self.start_linear = nn.Linear(2 * nhidden, 1)\n","        self.end_linear = nn.Linear(2 * nhidden, 1)\n","        self.ls = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, init_state, c_ids):\n","        _, max_c_len = c_ids.size()\n","        c_mask, c_lengths = return_mask_lengths(c_ids)\n","\n","        H = self.embedding(c_ids, c_mask)\n","        U = init_state.unsqueeze(1).repeat(1, max_c_len, 1)\n","        G = torch.cat([H, U, H * U, torch.abs(H - U)], dim=-1)\n","        M, _ = self.context_lstm(G, c_lengths)\n","\n","        start_logits = self.start_linear(M).squeeze(-1)\n","        end_logits = self.end_linear(M).squeeze(-1)\n","\n","        start_end_mask = (c_mask == 0)\n","        masked_start_logits = start_logits.masked_fill(\n","            start_end_mask, -10000.0)\n","        masked_end_logits = end_logits.masked_fill(start_end_mask, -10000.0)\n","\n","        return masked_start_logits, masked_end_logits\n","\n","    def generate(self, init_state, c_ids):\n","        start_logits, end_logits = self.forward(init_state, c_ids)\n","        c_mask, _ = return_mask_lengths(c_ids)\n","        batch_size, max_c_len = c_ids.size()\n","\n","        mask = torch.matmul(c_mask.unsqueeze(2).float(),\n","                            c_mask.unsqueeze(1).float())\n","        mask = torch.triu(mask) == 0\n","        score = (self.ls(start_logits).unsqueeze(2)\n","                 + self.ls(end_logits).unsqueeze(1))\n","        score = score.masked_fill(mask, -10000.0)\n","        score, start_positions = score.max(dim=1)\n","        score, end_positions = score.max(dim=1)\n","        start_positions = torch.gather(start_positions,\n","                                       1,\n","                                       end_positions.view(-1, 1)).squeeze(1)\n","\n","        idxes = torch.arange(0, max_c_len, out=torch.LongTensor(max_c_len))\n","        idxes = idxes.unsqueeze(0).to(\n","            start_logits.device).repeat(batch_size, 1)\n","\n","        start_positions = start_positions.unsqueeze(1)\n","        start_mask = (idxes >= start_positions).long()\n","        end_positions = end_positions.unsqueeze(1)\n","        end_mask = (idxes <= end_positions).long()\n","        a_ids = start_mask + end_mask - 1\n","\n","        return a_ids, start_positions.squeeze(1), end_positions.squeeze(1)\n","\n","class ContextEncoderforQG(nn.Module):\n","    def __init__(self, embedding, emsize,\n","                 nhidden, nlayers,\n","                 dropout=0.0):\n","        super(ContextEncoderforQG, self).__init__()\n","        self.embedding = embedding\n","        self.context_lstm = CustomLSTM(input_size=emsize,\n","                                       hidden_size=nhidden,\n","                                       num_layers=nlayers,\n","                                       dropout=dropout,\n","                                       bidirectional=True)\n","        self.context_linear = nn.Linear(2 * nhidden, 2 * nhidden)\n","        self.fusion = nn.Linear(4 * nhidden, 2 * nhidden, bias=False)\n","        self.gate = nn.Linear(4 * nhidden, 2 * nhidden, bias=False)\n","\n","    def forward(self, c_ids, a_ids):\n","        c_mask, c_lengths = return_mask_lengths(c_ids)\n","        c_embeddings = self.embedding(c_ids, c_mask, a_ids)\n","        c_outputs, _ = self.context_lstm(c_embeddings, c_lengths)\n","        # attention\n","        mask = torch.matmul(c_mask.unsqueeze(2), c_mask.unsqueeze(1))\n","        c_attned_by_c, _ = cal_attn(self.context_linear(c_outputs),\n","                                    c_outputs,\n","                                    mask)\n","        c_concat = torch.cat([c_outputs, c_attned_by_c], dim=2)\n","        c_fused = self.fusion(c_concat).tanh()\n","        c_gate = self.gate(c_concat).sigmoid()\n","        c_outputs = c_gate * c_fused + (1 - c_gate) * c_outputs\n","        return c_outputs\n","\n","class QuestionDecoder(nn.Module):\n","    def __init__(self, sos_id, eos_id,\n","                 embedding, contextualized_embedding, emsize,\n","                 nhidden, ntokens, nlayers,\n","                 dropout=0.0,\n","                 max_q_len=64):\n","        super(QuestionDecoder, self).__init__()\n","\n","        self.sos_id = sos_id\n","        self.eos_id = eos_id\n","        self.emsize = emsize\n","        self.embedding = embedding\n","        self.nhidden = nhidden\n","        self.ntokens = ntokens\n","        self.nlayers = nlayers\n","        # this max_len include sos eos\n","        self.max_q_len = max_q_len\n","\n","        self.context_lstm = ContextEncoderforQG(contextualized_embedding, emsize,\n","                                                nhidden // 2, nlayers, dropout)\n","\n","        self.question_lstm = CustomLSTM(input_size=emsize,\n","                                        hidden_size=nhidden,\n","                                        num_layers=nlayers,\n","                                        dropout=dropout,\n","                                        bidirectional=False)\n","\n","        self.question_linear = nn.Linear(nhidden, nhidden)\n","\n","        self.concat_linear = nn.Sequential(nn.Linear(2*nhidden, 2*nhidden),\n","                                           nn.Dropout(dropout),\n","                                           nn.Linear(2*nhidden, 2*emsize))\n","\n","        self.logit_linear = nn.Linear(emsize, ntokens, bias=False)\n","\n","        # fix output word matrix\n","        self.logit_linear.weight = embedding.word_embeddings.weight\n","        for param in self.logit_linear.parameters():\n","            param.requires_grad = False\n","\n","        self.discriminator = nn.Bilinear(emsize, nhidden, 1)\n","\n","    def postprocess(self, q_ids):\n","        eos_mask = q_ids == self.eos_id\n","        no_eos_idx_sum = (eos_mask.sum(dim=1) == 0).long() * \\\n","            (self.max_q_len - 1)\n","        eos_mask = eos_mask.cpu().numpy()\n","        q_lengths = np.argmax(eos_mask, axis=1) + 1\n","        q_lengths = torch.tensor(q_lengths).to(\n","            q_ids.device).long() + no_eos_idx_sum\n","        batch_size, max_len = q_ids.size()\n","        idxes = torch.arange(0, max_len).to(q_ids.device)\n","        idxes = idxes.unsqueeze(0).repeat(batch_size, 1)\n","        q_mask = (idxes < q_lengths.unsqueeze(1))\n","        q_ids = q_ids.long() * q_mask.long()\n","        return q_ids\n","\n","    def forward(self, init_state, c_ids, q_ids, a_ids):\n","        batch_size, max_q_len = q_ids.size()\n","\n","        c_outputs = self.context_lstm(c_ids, a_ids)\n","\n","        c_mask, _ = return_mask_lengths(c_ids)\n","        q_mask, q_lengths = return_mask_lengths(q_ids)\n","\n","        # question dec\n","        q_embeddings = self.embedding(q_ids)\n","        q_outputs, _ = self.question_lstm(q_embeddings, q_lengths, init_state)\n","\n","        # attention\n","        mask = torch.matmul(q_mask.unsqueeze(2), c_mask.unsqueeze(1))\n","        c_attned_by_q, attn_logits = cal_attn(self.question_linear(q_outputs),\n","                                              c_outputs,\n","                                              mask)\n","\n","        # gen logits\n","        q_concated = torch.cat([q_outputs, c_attned_by_q], dim=2)\n","        q_concated = self.concat_linear(q_concated)\n","        q_maxouted, _ = q_concated.view(\n","            batch_size, max_q_len, self.emsize, 2).max(dim=-1)\n","        gen_logits = self.logit_linear(q_maxouted)\n","\n","        # copy logits\n","        bq = batch_size * max_q_len\n","        c_ids = c_ids.unsqueeze(1).repeat(\n","            1, max_q_len, 1).view(bq, -1).contiguous()\n","        attn_logits = attn_logits.view(bq, -1).contiguous()\n","        copy_logits = torch.zeros(bq, self.ntokens).to(c_ids.device)\n","        copy_logits = copy_logits - 10000.0\n","        copy_logits, _ = scatter_max(attn_logits, c_ids, out=copy_logits)\n","        copy_logits = copy_logits.masked_fill(copy_logits == -10000.0, 0)\n","        copy_logits = copy_logits.view(batch_size, max_q_len, -1).contiguous()\n","\n","        logits = gen_logits + copy_logits\n","\n","        # mutual information btw answer and question\n","        a_emb = c_outputs * a_ids.float().unsqueeze(2)\n","        a_mean_emb = torch.sum(a_emb, 1) / a_ids.sum(1).unsqueeze(1).float()\n","        fake_a_mean_emb = torch.cat([a_mean_emb[-1].unsqueeze(0),\n","                                     a_mean_emb[:-1]], dim=0)\n","\n","        q_emb = q_maxouted * q_mask.unsqueeze(2)\n","        q_mean_emb = torch.sum(q_emb, 1) / q_lengths.unsqueeze(1).float()\n","        fake_q_mean_emb = torch.cat([q_mean_emb[-1].unsqueeze(0),\n","                                     q_mean_emb[:-1]], dim=0)\n","\n","        bce_loss = nn.BCEWithLogitsLoss()\n","        true_logits = self.discriminator(q_mean_emb, a_mean_emb)\n","        true_labels = torch.ones_like(true_logits)\n","\n","        fake_a_logits = self.discriminator(q_mean_emb, fake_a_mean_emb)\n","        fake_q_logits = self.discriminator(fake_q_mean_emb, a_mean_emb)\n","        fake_logits = torch.cat([fake_a_logits, fake_q_logits], dim=0)\n","        fake_labels = torch.zeros_like(fake_logits)\n","\n","        true_loss = bce_loss(true_logits, true_labels)\n","        fake_loss = 0.5 * bce_loss(fake_logits, fake_labels)\n","        loss_info = 0.5 * (true_loss + fake_loss)\n","\n","        return logits, loss_info, q_maxouted\n","\n","    def generate(self, init_state, c_ids, a_ids):\n","        c_mask, _ = return_mask_lengths(c_ids)\n","        c_outputs = self.context_lstm(c_ids, a_ids)\n","\n","        batch_size = c_ids.size(0)\n","\n","        q_ids = torch.LongTensor([self.sos_id] * batch_size).unsqueeze(1)\n","        q_ids = q_ids.to(c_ids.device)\n","        token_type_ids = torch.zeros_like(q_ids)\n","        position_ids = torch.zeros_like(q_ids)\n","        q_embeddings = self.embedding(q_ids, token_type_ids, position_ids)\n","\n","        state = init_state\n","\n","        # unroll\n","        all_q_ids = list()\n","        all_q_ids.append(q_ids)\n","        for _ in range(self.max_q_len - 1):\n","            position_ids = position_ids + 1\n","            q_outputs, state = self.question_lstm.lstm(q_embeddings, state)\n","\n","            # attention\n","            mask = c_mask.unsqueeze(1)\n","            c_attned_by_q, attn_logits = cal_attn(self.question_linear(q_outputs),\n","                                                  c_outputs,\n","                                                  mask)\n","\n","            # gen logits\n","            q_concated = torch.cat([q_outputs, c_attned_by_q], dim=2)\n","            q_concated = self.concat_linear(q_concated)\n","            q_maxouted, _ = q_concated.view(\n","                batch_size, 1, self.emsize, 2).max(dim=-1)\n","            gen_logits = self.logit_linear(q_maxouted)\n","\n","            # copy logits\n","            attn_logits = attn_logits.squeeze(1)\n","            copy_logits = torch.zeros(\n","                batch_size, self.ntokens).to(c_ids.device)\n","            copy_logits = copy_logits - 10000.0\n","            copy_logits, _ = scatter_max(attn_logits, c_ids, out=copy_logits)\n","            copy_logits = copy_logits.masked_fill(copy_logits == -10000.0, 0)\n","\n","            logits = gen_logits + copy_logits.unsqueeze(1)\n","\n","            q_ids = torch.argmax(logits, 2)\n","            all_q_ids.append(q_ids)\n","\n","            q_embeddings = self.embedding(q_ids, token_type_ids, position_ids)\n","\n","        q_ids = torch.cat(all_q_ids, 1)\n","        q_ids = self.postprocess(q_ids)\n","\n","        return q_ids\n","\n","    def sample(self, init_state, c_ids, a_ids):\n","        c_mask, c_lengths = return_mask_lengths(c_ids)\n","        c_outputs = self.context_lstm(c_ids, a_ids)\n","\n","        batch_size = c_ids.size(0)\n","\n","        q_ids = torch.LongTensor([self.sos_id] * batch_size).unsqueeze(1)\n","        q_ids = q_ids.to(c_ids.device)\n","        token_type_ids = torch.zeros_like(q_ids)\n","        position_ids = torch.zeros_like(q_ids)\n","        q_embeddings = self.embedding(q_ids, token_type_ids, position_ids)\n","\n","        state = init_state\n","\n","        # unroll\n","        all_q_ids = list()\n","        all_q_ids.append(q_ids)\n","        for _ in range(self.max_q_len - 1):\n","            position_ids = position_ids + 1\n","            q_outputs, state = self.question_lstm.lstm(q_embeddings, state)\n","\n","            # attention\n","            mask = c_mask.unsqueeze(1)\n","            c_attned_by_q, attn_logits = cal_attn(self.question_linear(q_outputs),\n","                                                  c_outputs,\n","                                                  mask)\n","\n","            # gen logits\n","            q_concated = torch.cat([q_outputs, c_attned_by_q], dim=2)\n","            q_concated = self.concat_linear(q_concated)\n","            q_maxouted, _ = q_concated.view(batch_size, 1, self.emsize, 2).max(dim=-1)\n","            gen_logits = self.logit_linear(q_maxouted)\n","\n","            # copy logits\n","            attn_logits = attn_logits.squeeze(1)\n","            copy_logits = torch.zeros(batch_size, self.ntokens).to(c_ids.device)\n","            copy_logits = copy_logits - 10000.0\n","            copy_logits, _ = scatter_max(attn_logits, c_ids, out=copy_logits)\n","            copy_logits = copy_logits.masked_fill(copy_logits == -10000.0, 0)\n","\n","            logits = gen_logits + copy_logits.unsqueeze(1)\n","            logits = logits.squeeze(1)\n","            logits = self.top_k_top_p_filtering(logits, 2, top_p=0.8)\n","            probs = F.softmax(logits, dim=-1)\n","            q_ids = torch.multinomial(probs, num_samples=1)  # [b,1]\n","            all_q_ids.append(q_ids)\n","\n","            q_embeddings = self.embedding(q_ids, token_type_ids, position_ids)\n","\n","        q_ids = torch.cat(all_q_ids, 1)\n","        q_ids = self.postprocess(q_ids)\n","\n","        return q_ids\n","\n","class DistractorDecoder(nn.Module):\n","    def __init__(self, sos_id, eos_id,\n","                 embedding, contextualized_embedding, emsize,\n","                 nhidden, ntokens, nlayers,\n","                 dropout=0.0,\n","                 max_d_len=64):\n","        super(DistractorDecoder, self).__init__()\n","\n","        self.sos_id = sos_id\n","        self.eos_id = eos_id\n","        self.emsize = emsize\n","        self.embedding = embedding\n","        self.nhidden = nhidden\n","        self.ntokens = ntokens\n","        self.nlayers = nlayers\n","        # this max_len include sos eos\n","        self.max_d_len = max_d_len \n","\n","        self.context_lstm = ContextEncoderforQG(contextualized_embedding, emsize,\n","                                                nhidden // 2, nlayers, dropout)\n","\n","        self.distractor_lstm = CustomLSTM(input_size=emsize,\n","                                        hidden_size=nhidden,\n","                                        num_layers=nlayers,\n","                                        dropout=dropout,\n","                                        bidirectional=False) ## make true?\n","\n","        self.distractor_linear = nn.Linear(nhidden, nhidden)\n","\n","        self.concat_linear = nn.Sequential(nn.Linear(2*nhidden, 2*nhidden),\n","                                           nn.Dropout(dropout),\n","                                           nn.Linear(2*nhidden, 2*emsize))\n","\n","        self.logit_linear = nn.Linear(emsize, ntokens, bias=False)\n","\n","        # fix output word matrix\n","        self.logit_linear.weight = embedding.word_embeddings.weight\n","        for param in self.logit_linear.parameters():\n","            param.requires_grad = False\n","\n","        self.discriminator = nn.Bilinear(emsize, nhidden, 1)\n","        self.discriminator2 = nn.Bilinear(emsize, emsize, 1)\n","\n","    def postprocess(self, d_ids):\n","        eos_mask = d_ids == self.eos_id\n","        no_eos_idx_sum = (eos_mask.sum(dim=1) == 0).long() * \\\n","            (self.max_d_len - 1)\n","        eos_mask = eos_mask.cpu().numpy()\n","        d_lengths = np.argmax(eos_mask, axis=1) + 1\n","        d_lengths = torch.tensor(d_lengths).to(\n","            d_ids.device).long() + no_eos_idx_sum\n","        batch_size, max_len = d_ids.size()\n","        idxes = torch.arange(0, max_len).to(d_ids.device)\n","        idxes = idxes.unsqueeze(0).repeat(batch_size, 1)\n","        d_mask = (idxes < d_lengths.unsqueeze(1))\n","        d_ids = d_ids.long() * d_mask.long()\n","        return d_ids\n","\n","    def forward(self, init_state, c_ids, q_ids, a_ids,d_ids,q_maxouted):\n","        batch_size, max_d_len = d_ids.size()\n","\n","        c_outputs = self.context_lstm(c_ids, a_ids)\n","\n","        c_mask, _ = return_mask_lengths(c_ids)\n","        d_mask, d_lengths = return_mask_lengths(d_ids)\n","        q_mask, q_lengths = return_mask_lengths(q_ids)\n","\n","        # distractor dec\n","        d_embeddings = self.embedding(d_ids)\n","        d_outputs, _ = self.distractor_lstm(d_embeddings, d_lengths, init_state)\n","\n","        # attention\n","        mask = torch.matmul(d_mask.unsqueeze(2), c_mask.unsqueeze(1))\n","        c_attned_by_d, attn_logits = cal_attn(self.distractor_linear(d_outputs),\n","                                              c_outputs,\n","                                              mask)\n","\n","        # gen logits\n","        d_concated = torch.cat([d_outputs, c_attned_by_d], dim=2)\n","        d_concated = self.concat_linear(d_concated)\n","        d_maxouted, _ = d_concated.view(\n","            batch_size, max_d_len, self.emsize, 2).max(dim=-1)\n","        gen_logits = self.logit_linear(d_maxouted)\n","\n","        # copy logits\n","        bd = batch_size * max_d_len\n","        c_ids = c_ids.unsqueeze(1).repeat(\n","            1, max_d_len, 1).view(bd, -1).contiguous()\n","        attn_logits = attn_logits.view(bd, -1).contiguous()\n","        copy_logits = torch.zeros(bd, self.ntokens).to(c_ids.device)\n","        copy_logits = copy_logits - 10000.0\n","        copy_logits, _ = scatter_max(attn_logits, c_ids, out=copy_logits)\n","        copy_logits = copy_logits.masked_fill(copy_logits == -10000.0, 0)\n","        copy_logits = copy_logits.view(batch_size, max_d_len, -1).contiguous()\n","\n","        logits = gen_logits + copy_logits\n","\n","        # mutual information btw answer and distractor\n","        a_emb = c_outputs * a_ids.float().unsqueeze(2)\n","        a_mean_emb = torch.sum(a_emb, 1) / a_ids.sum(1).unsqueeze(1).float()\n","        fake_a_mean_emb = torch.cat([a_mean_emb[-1].unsqueeze(0),\n","                                     a_mean_emb[:-1]], dim=0)\n","\n","        d_emb = d_maxouted * d_mask.unsqueeze(2)\n","        d_mean_emb = torch.sum(d_emb, 1) / d_lengths.unsqueeze(1).float()\n","        fake_d_mean_emb = torch.cat([d_mean_emb[-1].unsqueeze(0),\n","                                     d_mean_emb[:-1]], dim=0)\n","\n","        bce_loss = nn.BCEWithLogitsLoss()\n","        true_logits = self.discriminator(d_mean_emb, a_mean_emb)\n","        true_labels = torch.ones_like(true_logits)\n","\n","        fake_a_logits = self.discriminator(d_mean_emb, fake_a_mean_emb)\n","        fake_d_logits = self.discriminator(fake_d_mean_emb, a_mean_emb)\n","        fake_logits = torch.cat([fake_a_logits, fake_d_logits], dim=0)\n","        fake_labels = torch.zeros_like(fake_logits)\n","\n","        true_loss = bce_loss(true_logits, true_labels)\n","        fake_loss = 0.5 * bce_loss(fake_logits, fake_labels)\n","        loss_info_with_answer = 0.5 * (true_loss + fake_loss)\n","\n","        # mutual information btw distractor and question\n","        d_emb = d_maxouted * d_mask.unsqueeze(2)\n","        d_mean_emb = torch.sum(d_emb, 1) / d_lengths.unsqueeze(1).float()\n","        fake_d_mean_emb = torch.cat([d_mean_emb[-1].unsqueeze(0),\n","                                     d_mean_emb[:-1]], dim=0)\n","\n","        q_emb = q_maxouted * q_mask.unsqueeze(2)\n","        q_mean_emb = torch.sum(q_emb, 1) / q_lengths.unsqueeze(1).float()\n","        fake_q_mean_emb = torch.cat([q_mean_emb[-1].unsqueeze(0),\n","                                     q_mean_emb[:-1]], dim=0)\n","\n","        bce_loss = nn.BCEWithLogitsLoss()\n","        true_logits = self.discriminator2(q_mean_emb, d_mean_emb)\n","        true_labels = torch.ones_like(true_logits)\n","\n","        fake_d_logits = self.discriminator2(q_mean_emb, fake_d_mean_emb)\n","        fake_q_logits = self.discriminator2(fake_q_mean_emb, d_mean_emb)\n","        fake_logits = torch.cat([fake_d_logits, fake_q_logits], dim=0)\n","        fake_labels = torch.zeros_like(fake_logits)\n","\n","        true_loss = bce_loss(true_logits, true_labels)\n","        fake_loss = 0.5 * bce_loss(fake_logits, fake_labels)\n","        loss_info_with_question = 0.5 * (true_loss + fake_loss)\n","        \n","        return logits, loss_info_with_answer,loss_info_with_question\n","\n","    def generate(self, init_state, c_ids, a_ids,q_ids):\n","        c_mask, _ = return_mask_lengths(c_ids)\n","        c_outputs = self.context_lstm(c_ids, a_ids) ## here\n","\n","        batch_size = c_ids.size(0)\n","\n","        d_ids = torch.LongTensor([self.sos_id] * batch_size).unsqueeze(1)\n","        d_ids = d_ids.to(c_ids.device)\n","        token_type_ids = torch.zeros_like(d_ids)\n","        position_ids = torch.zeros_like(d_ids)\n","        d_embeddings = self.embedding(d_ids, token_type_ids, position_ids)\n","\n","        state = init_state\n","\n","        # unroll\n","        all_d_ids = list()\n","        all_d_ids.append(d_ids)\n","        for _ in range(self.max_d_len - 1):\n","            position_ids = position_ids + 1\n","            d_outputs, state = self.distractor_lstm.lstm(d_embeddings, state)\n","\n","            # attention\n","            mask = c_mask.unsqueeze(1)\n","            c_attned_by_d, attn_logits = cal_attn(self.distractor_linear(d_outputs),\n","                                                  c_outputs,\n","                                                  mask)\n","\n","            # gen logits\n","            d_concated = torch.cat([d_outputs, c_attned_by_d], dim=2)\n","            d_concated = self.concat_linear(d_concated)\n","            d_maxouted, _ = d_concated.view(\n","                batch_size, 1, self.emsize, 2).max(dim=-1)\n","            gen_logits = self.logit_linear(d_maxouted)\n","\n","            # copy logits\n","            attn_logits = attn_logits.squeeze(1)\n","            copy_logits = torch.zeros(\n","                batch_size, self.ntokens).to(c_ids.device)\n","            copy_logits = copy_logits - 10000.0\n","            copy_logits, _ = scatter_max(attn_logits, c_ids, out=copy_logits)\n","            copy_logits = copy_logits.masked_fill(copy_logits == -10000.0, 0)\n","\n","            logits = gen_logits + copy_logits.unsqueeze(1)\n","\n","            d_ids = torch.argmax(logits, 2)\n","            all_d_ids.append(d_ids)\n","\n","            d_embeddings = self.embedding(d_ids, token_type_ids, position_ids)\n","\n","        d_ids = torch.cat(all_d_ids, 1)\n","        d_ids = self.postprocess(d_ids)\n","\n","        return d_ids\n","\n","    def sample(self, init_state, c_ids, a_ids,q_ids):\n","        c_mask, c_lengths = return_mask_lengths(c_ids)\n","        c_outputs = self.context_lstm(c_ids, a_ids)\n","\n","        batch_size = c_ids.size(0)\n","\n","        d_ids = torch.LongTensor([self.sos_id] * batch_size).unsqueeze(1)\n","        d_ids = d_ids.to(c_ids.device)\n","        token_type_ids = torch.zeros_like(d_ids)\n","        position_ids = torch.zeros_like(d_ids)\n","        d_embeddings = self.embedding(d_ids, token_type_ids, position_ids)\n","\n","        state = init_state\n","\n","        # unroll\n","        all_d_ids = list()\n","        all_d_ids.append(d_ids)\n","        for _ in range(self.max_q_len - 1):\n","            position_ids = position_ids + 1\n","            d_outputs, state = self.distractor_lstm.lstm(d_embeddings, state)\n","\n","            # attention\n","            mask = c_mask.unsqueeze(1)\n","            c_attned_by_d, attn_logits = cal_attn(self.question_linear(d_outputs),\n","                                                  c_outputs,\n","                                                  mask)\n","\n","            # gen logits\n","            d_concated = torch.cat([d_outputs, c_attned_by_d], dim=2)\n","            d_concated = self.concat_linear(d_concated)\n","            d_maxouted, _ = d_concated.view(batch_size, 1, self.emsize, 2).max(dim=-1)\n","            gen_logits = self.logit_linear(d_maxouted)\n","\n","            # copy logits\n","            attn_logits = attn_logits.squeeze(1)\n","            copy_logits = torch.zeros(batch_size, self.ntokens).to(c_ids.device)\n","            copy_logits = copy_logits - 10000.0\n","            copy_logits, _ = scatter_max(attn_logits, c_ids, out=copy_logits)\n","            copy_logits = copy_logits.masked_fill(copy_logits == -10000.0, 0)\n","\n","            logits = gen_logits + copy_logits.unsqueeze(1)\n","            logits = logits.squeeze(1)\n","            logits = self.top_k_top_p_filtering(logits, 2, top_p=0.8)\n","            probs = F.softmax(logits, dim=-1)\n","            d_ids = torch.multinomial(probs, num_samples=1)  # [b,1]\n","            all_d_ids.append(d_ids)\n","\n","            d_embeddings = self.embedding(d_ids, token_type_ids, position_ids)\n","\n","        d_ids = torch.cat(all_d_ids, 1)\n","        d_ids = self.postprocess(d_ids)\n","\n","        return d_ids\n","\n","class DiscreteVAE(nn.Module):\n","    def __init__(self, args):\n","        super(DiscreteVAE, self).__init__()\n","        tokenizer = BertTokenizer.from_pretrained(args.bert_model)\n","        padding_idx = tokenizer.vocab['[PAD]']\n","        sos_id = tokenizer.vocab['[CLS]']\n","        eos_id = tokenizer.vocab['[SEP]']\n","        ntokens = len(tokenizer.vocab)\n","\n","        bert_model = args.bert_model\n","        if \"large\" in bert_model:\n","            emsize = 1024\n","        else:\n","            emsize = 768\n","\n","        enc_nhidden = args.enc_nhidden\n","        enc_nlayers = args.enc_nlayers\n","        enc_dropout = args.enc_dropout\n","        dec_a_nhidden = args.dec_a_nhidden\n","        dec_a_nlayers = args.dec_a_nlayers\n","        dec_a_dropout = args.dec_a_dropout\n","        self.dec_q_nhidden = dec_q_nhidden = args.dec_q_nhidden\n","        self.dec_q_nlayers = dec_q_nlayers = args.dec_q_nlayers\n","        self.dec_d_nhidden = dec_d_nhidden = args.dec_d_nhidden\n","        self.dec_d_nlayers = dec_d_nlayers = args.dec_d_nlayers\n","        dec_q_dropout = args.dec_q_dropout\n","        dec_d_dropout = args.dec_d_dropout\n","        self.nzqdim = nzqdim = args.nzqdim\n","        self.nzddim = nzddim = args.nzddim\n","        self.nza = nza = args.nza\n","        self.nzadim = nzadim = args.nzadim\n","\n","        self.lambda_kl = args.lambda_kl\n","        self.lambda_info = args.lambda_info\n","\n","        max_q_len = args.max_q_len\n","        max_d_len = args.max_d_len\n","\n","        embedding = Embedding(bert_model)\n","        contextualized_embedding = ContextualizedEmbedding(bert_model)\n","        # freeze embedding\n","        for param in embedding.parameters():\n","            param.requires_grad = False\n","        for param in contextualized_embedding.parameters():\n","            param.requires_grad = False\n","\n","        self.posterior_encoder = PosteriorEncoder(embedding, emsize,\n","                                                  enc_nhidden, enc_nlayers,\n","                                                  nzqdim, nza, nzadim,nzddim,\n","                                                  enc_dropout)\n","\n","        self.prior_encoder = PriorEncoder(embedding, emsize,\n","                                          enc_nhidden, enc_nlayers,\n","                                          nzqdim, nza, nzadim,nzddim, enc_dropout)\n","\n","        self.answer_decoder = AnswerDecoder(contextualized_embedding, emsize,\n","                                            dec_a_nhidden, dec_a_nlayers,\n","                                            dec_a_dropout)\n","\n","        self.question_decoder = QuestionDecoder(sos_id, eos_id,\n","                                                embedding, contextualized_embedding, emsize,\n","                                                dec_q_nhidden, ntokens, dec_q_nlayers,\n","                                                dec_q_dropout,\n","                                                max_q_len)\n","\n","        self.distractor_decoder = DistractorDecoder(sos_id, eos_id,\n","                                                embedding, contextualized_embedding, emsize,\n","                                                dec_d_nhidden, ntokens, dec_d_nlayers,\n","                                                dec_d_dropout,\n","                                                max_d_len)\n","\n","        self.q_h_linear = nn.Linear(nzqdim, dec_q_nlayers * dec_q_nhidden)\n","        self.q_c_linear = nn.Linear(nzqdim, dec_q_nlayers * dec_q_nhidden)\n","        self.d_h_linear = nn.Linear(nzddim, dec_d_nlayers * dec_d_nhidden)\n","        self.d_c_linear = nn.Linear(nzddim, dec_d_nlayers * dec_d_nhidden)\n","        self.a_linear = nn.Linear(nza * nzadim, emsize, False)\n","\n","        self.q_rec_criterion = nn.CrossEntropyLoss(ignore_index=padding_idx)\n","        self.d_rec_criterion = nn.CrossEntropyLoss(ignore_index=padding_idx)\n","        self.gaussian_kl_criterion = GaussianKLLoss()\n","        self.categorical_kl_criterion = CategoricalKLLoss()\n","\n","    def return_init_state(self, zq, za, zd):\n","\n","        q_init_h = self.q_h_linear(zq)\n","        q_init_c = self.q_c_linear(zq)\n","        d_init_h = self.d_h_linear(zd)\n","        d_init_c = self.d_c_linear(zd)\n","\n","        q_init_h = q_init_h.view(-1, self.dec_q_nlayers,\n","                                 self.dec_q_nhidden).transpose(0, 1).contiguous()\n","        q_init_c = q_init_c.view(-1, self.dec_q_nlayers,\n","                                 self.dec_q_nhidden).transpose(0, 1).contiguous()\n","        q_init_state = (q_init_h, q_init_c)\n","\n","        ##\n","        d_init_h = d_init_h.view(-1, self.dec_d_nlayers,\n","                                 self.dec_d_nhidden).transpose(0, 1).contiguous()\n","        d_init_c = d_init_c.view(-1, self.dec_d_nlayers,\n","                                 self.dec_d_nhidden).transpose(0, 1).contiguous()\n","        d_init_state = (d_init_h, d_init_c)\n","        ##\n","\n","        za_flatten = za.view(-1, self.nza * self.nzadim)\n","        a_init_state = self.a_linear(za_flatten)\n","\n","        return q_init_state, a_init_state,d_init_state\n","\n","\n","    def forward(self, c_ids, q_ids, a_ids, start_positions, end_positions,d_ids):\n","\n","        posterior_zq_mu, posterior_zq_logvar, posterior_zq, \\\n","            posterior_za_prob, posterior_za, \\\n","            posterior_zd_mu, posterior_zd_logvar, posterior_zd \\\n","            = self.posterior_encoder(c_ids, q_ids, a_ids,d_ids)\n","\n","        prior_zq_mu, prior_zq_logvar, _, \\\n","            prior_za_prob, _, \\\n","            prior_zd_mu, prior_zd_logvar, _ \\\n","            = self.prior_encoder(c_ids)\n","\n","        q_init_state, a_init_state, d_init_state = self.return_init_state(\n","            posterior_zq, posterior_za,posterior_zd)\n","\n","        # answer decoding\n","        start_logits, end_logits = self.answer_decoder(a_init_state, c_ids)\n","        # question decoding\n","        q_logits, loss_info, q_maxouted = self.question_decoder(\n","            q_init_state, c_ids, q_ids, a_ids)        \n","        # distractor decoding\n","        d_logits, d_loss_info_with_answer,d_loss_info_with_question = self.distractor_decoder(\n","            d_init_state, c_ids, q_ids, a_ids,d_ids,q_maxouted)\n","\n","        # q rec loss\n","        loss_q_rec = self.q_rec_criterion(q_logits[:, :-1, :].transpose(1, 2).contiguous(),\n","                                          q_ids[:, 1:])\n","\n","        # a rec loss\n","        max_c_len = c_ids.size(1)\n","        a_rec_criterion = nn.CrossEntropyLoss(ignore_index=max_c_len)\n","        start_positions.clamp_(0, max_c_len)\n","        end_positions.clamp_(0, max_c_len)\n","        loss_start_a_rec = a_rec_criterion(start_logits, start_positions)\n","        loss_end_a_rec = a_rec_criterion(end_logits, end_positions)\n","        loss_a_rec = 0.5 * (loss_start_a_rec + loss_end_a_rec)\n","\n","        # d rec loss\n","        loss_d_rec = self.d_rec_criterion(d_logits[:, :-1, :].transpose(1, 2).contiguous(),\n","                                          d_ids[:, 1:])\n","\n","        # kl loss\n","        loss_zq_kl = self.gaussian_kl_criterion(posterior_zq_mu,\n","                                                posterior_zq_logvar,\n","                                                prior_zq_mu,\n","                                                prior_zq_logvar)\n","        # kl loss for d\n","        loss_zd_kl = self.gaussian_kl_criterion(posterior_zd_mu,\n","                                                posterior_zd_logvar,\n","                                                prior_zd_mu,\n","                                                prior_zd_logvar)\n","\n","        loss_za_kl = self.categorical_kl_criterion(posterior_za_prob,\n","                                                   prior_za_prob)\n","\n","        loss_kl = self.lambda_kl * (loss_zq_kl + loss_za_kl+loss_zd_kl)\n","        loss_info = self.lambda_info * loss_info\n","        loss_info_d_q = self.lambda_info * d_loss_info_with_question\n","        loss_info_d_ans = self.lambda_info * d_loss_info_with_answer\n","        loss = loss_q_rec + loss_a_rec + loss_kl + loss_info + loss_d_rec + loss_info_d_q + loss_info_d_ans\n","\n","        return loss, \\\n","            loss_q_rec, loss_a_rec, \\\n","            loss_zq_kl, loss_za_kl, \\\n","            loss_info, loss_d_rec,loss_zd_kl, loss_info_d_q,loss_info_d_ans\n","\n","    def generate(self, zq, za, c_ids,zd):\n","        q_init_state, a_init_state, d_init_state = self.return_init_state(zq, za,zd)\n","\n","        a_ids, start_positions, end_positions = self.answer_decoder.generate(   ## answer generation\n","            a_init_state, c_ids)\n","\n","        q_ids = self.question_decoder.generate(q_init_state, c_ids, a_ids) \n","        d_ids = self.distractor_decoder.generate(d_init_state, c_ids, a_ids, q_ids)       ## question generation\n","\n","        return q_ids, start_positions, end_positions, d_ids\n","\n","    def return_answer_logits(self, zq, za, c_ids,zd):\n","        _, a_init_state, _ = self.return_init_state(zq, za, zd)\n","\n","        start_logits, end_logits = self.answer_decoder(a_init_state, c_ids)\n","\n","        return start_logits, end_logits"],"metadata":{"id":"IDg8huw0-Itn","executionInfo":{"status":"ok","timestamp":1676467695846,"user_tz":0,"elapsed":1052,"user":{"displayName":"Ayush Modi","userId":"15866713891896926467"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# from trainerCustom import VAETrainer\n","# from modelsCustom import DiscreteVAE, return_mask_lengths"],"metadata":{"id":"R4cl7Cc5h4FQ","executionInfo":{"status":"ok","timestamp":1676467695847,"user_tz":0,"elapsed":12,"user":{"displayName":"Ayush Modi","userId":"15866713891896926467"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","def setArguments():\n","    args = dict()\n","    args[\"seed\"]=1004\n","    args[\"debug\"]=True\n","    args[\"train_dir\"]='../data/sciq/squad_format/test.json'\n","    args[\"dev_dir\"]='../data/sciq/squad_format/test.json'\n","\n","    args[\"max_c_len\"]=384\n","    args[\"max_q_len\"]=64\n","    args['max_d_len']=5\n","\n","    args[\"model_dir\"]=\"../save/vae-checkpoint\"\n","    args[\"epochs\"]=20\n","    args[\"lr\"]=1e-3\n","    args[\"batch_size\"]=13\n","    args[\"weight_decay\"]=0.0\n","    args[\"clip\"]=5.0\n","\n","    args[\"bert_model\"]='bert-base-uncased'\n","    args[\"enc_nhidden\"]=300\n","    args[\"enc_nlayers\"]=1\n","    args[\"enc_dropout\"]=0.2\n","    args[\"dec_a_nhidden\"]=300\n","    args[\"dec_a_nlayers\"]=1\n","    args[\"dec_a_dropout\"]=0.2\n","    args[\"dec_q_nhidden\"]=900\n","    args[\"dec_q_nlayers\"]=2\n","    args[\"dec_q_dropout\"]=0.3\n","    args['dec_d_nhidden']=900\n","    args['dec_d_nlayers']=2\n","    args['dec_d_dropout']=0.3\n","    args[\"nzqdim\"]=50\n","    args['nzddim']=50\n","    args[\"nza\"]=20\n","    args[\"nzadim\"]=10\n","    args[\"lambda_kl\"]=0.1\n","    args[\"lambda_info\"]=1.0\n","    return dotdict(args)\n","args = setArguments()\n","\n","if args.debug:\n","    print(\"Debug Mode On.\")\n","    args.model_dir = \"./dummy\"\n","# set model dir\n","model_dir = args.model_dir\n","os.makedirs(model_dir, exist_ok=True)\n","args.model_dir = os.path.abspath(model_dir)\n","\n","random.seed(args.seed)\n","np.random.seed(args.seed)\n","torch.manual_seed(args.seed)\n","torch.cuda.manual_seed(args.seed)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RTm-c3BJkEJ4","executionInfo":{"status":"ok","timestamp":1676467695848,"user_tz":0,"elapsed":11,"user":{"displayName":"Ayush Modi","userId":"15866713891896926467"}},"outputId":"92d5c7b0-ef26-4190-dbd7-fc54da4551a8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Debug Mode On.\n"]}]},{"cell_type":"code","source":["class VAETrainer(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.clip = args.clip\n","        self.device = args.device\n","\n","        self.vae = DiscreteVAE(args).to(self.device)\n","        params = filter(lambda p: p.requires_grad, self.vae.parameters())\n","        self.optimizer = torch.optim.Adam(params, lr=args.lr)\n","\n","        self.loss_q_rec = 0\n","        self.loss_a_rec = 0\n","        self.loss_d_rec = 0\n","        self.loss_zq_kl = 0\n","        self.loss_za_kl = 0\n","        self.loss_zd_kl = 0\n","        self.loss_info = 0\n","\n","    def train(self, c_ids, q_ids, a_ids, start_positions, end_positions,d_ids):\n","        self.vae = self.vae.train()\n","        # Forward\n","        loss, \\\n","        loss_q_rec, loss_a_rec, \\\n","        loss_zq_kl, loss_za_kl, \\\n","        loss_info, loss_d_rec, loss_zd_kl, loss_info_d_q,loss_info_d_ans \\\n","        = self.vae(c_ids, q_ids, a_ids, start_positions, end_positions,d_ids)\n","        # Backward\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","\n","        # Step\n","        self.optimizer.step()\n","\n","        self.loss_q_rec = loss_q_rec.item()\n","        self.loss_a_rec = loss_a_rec.item()\n","        self.loss_zq_kl = loss_zq_kl.item()\n","        self.loss_za_kl = loss_za_kl.item()\n","        self.loss_zd_kl = loss_zd_kl.item()\n","        self.loss_info = loss_info.item()\n","        self.loss_info_d_q=loss_info_d_q.item()\n","        self.loss_info_d_ans=loss_info_d_ans.item()\n","        self.loss_d_rec = loss_d_rec.item()\n","\n","    def generate_posterior(self, c_ids, q_ids, a_ids,d_ids):\n","        self.vae = self.vae.eval()\n","        with torch.no_grad():\n","            _, _, zq, _, za, _, _, zd = self.vae.posterior_encoder(c_ids, q_ids, a_ids,d_ids)\n","            q_ids, start_positions, end_positions, d_ids = self.vae.generate(zq, za, c_ids, zd)\n","        return q_ids, start_positions, end_positions, zq, d_ids, zd\n","\n","    def generate_answer_logits(self, c_ids, q_ids, a_ids, d_ids):\n","        self.vae = self.vae.eval()\n","        with torch.no_grad():\n","            _, _, zq, _, za, _, _, zd = self.vae.posterior_encoder(c_ids, q_ids, a_ids, d_ids)\n","            start_logits, end_logits = self.vae.return_answer_logits(zq, za, c_ids, zd)\n","        return start_logits, end_logits\n","\n","    def generate_prior(self, c_ids):\n","        self.vae = self.vae.eval()\n","        with torch.no_grad():\n","            _, _, zq, _, za, _, _, zd = self.vae.prior_encoder(c_ids)\n","            q_ids, start_positions, end_positions, d_ids = self.vae.generate(zq, za, c_ids, zd)\n","        return q_ids, start_positions, end_positions, zq, d_ids, zd    \n","\n","    def save(self, filename):\n","        params = {\n","            'state_dict': self.vae.state_dict(),\n","            'args': self.args\n","        }\n","        torch.save(params, filename)\n"],"metadata":{"id":"3RgzDA7E9Kf5","executionInfo":{"status":"ok","timestamp":1676467695848,"user_tz":0,"elapsed":9,"user":{"displayName":"Ayush Modi","userId":"15866713891896926467"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def main(args):\n","    tokenizer = BertTokenizer.from_pretrained(args.bert_model)\n","    train_loader, _, _ = get_squad_data_loader(tokenizer, args.train_dir,\n","                                         shuffle=True, args=args)\n","    eval_data = get_squad_data_loader(tokenizer, args.dev_dir,\n","                                      shuffle=False, args=args)\n","\n","    args.device = torch.cuda.current_device()\n","\n","    trainer = VAETrainer(args)\n","\n","    loss_log1 = tqdm(total=0, bar_format='{desc}')\n","    loss_log2 = tqdm(total=0, bar_format='{desc}')\n","    loss_log3 = tqdm(total=0, bar_format='{desc}')\n","    eval_log = tqdm(total=0, bar_format='{desc}')\n","    best_eval_log = tqdm(total=0, bar_format='{desc}')\n","\n","    print(\"MODEL DIR: \" + args.model_dir)\n","\n","    best_bleu, best_bleu_d, best_em, best_f1 = 0.0, 0.0, 0.0, 0.0\n","    for epoch in trange(int(args.epochs), desc=\"Epoch\", position=0):\n","        for batch in tqdm(train_loader, desc=\"Train iter\", leave=False, position=1):\n","            c_ids, q_ids, a_ids, start_positions, end_positions,d_ids \\\n","            = batch_to_device(batch, args.device)\n","            print(c_ids.shape)\n","            print(tokenizer.decode(c_ids[1]))\n","            return c_ids\n","            # raise\n","            trainer.train(c_ids, q_ids, a_ids, start_positions, end_positions,d_ids)\n","            \n","            str1 = 'Q REC : {:06.4f} A REC : {:06.4f} D REC : {:06.4f}'\n","            str2 = 'ZQ KL : {:06.4f} ZA KL : {:06.4f} ZD KL : {:06.4f}'\n","            str3 = 'L_INFO : {:06.4f}  L_INFO_D_Q : {:06.4f} INFO_D_ANS : {:06.4f}'\n","            str1 = str1.format(float(trainer.loss_q_rec), float(trainer.loss_a_rec), float(trainer.loss_d_rec))\n","            str2 = str2.format(float(trainer.loss_zq_kl), float(trainer.loss_za_kl), float(trainer.loss_zd_kl))\n","            str3 = str3.format(float(trainer.loss_info), float(trainer.loss_info_d_q), float(trainer.loss_info_d_ans))\n","            loss_log1.set_description_str(str1)\n","            loss_log2.set_description_str(str2)\n","            loss_log3.set_description_str(str3)\n","\n","        if epoch >= 10:\n","            metric_dict, bleu, _, bleu_d = eval_vae(epoch, args, trainer, eval_data)\n","            f1 = metric_dict[\"f1\"]\n","            em = metric_dict[\"exact_match\"]\n","            bleu = bleu * 100\n","            bleu_d = bleu_d * 100\n","            _str = '{}-th Epochs Q-BLEU : {:02.2f} D-BLEU : {:02.2f} EM : {:02.2f} F1 : {:02.2f}'\n","            _str = _str.format(epoch, bleu, bleu_d, em, f1)\n","            eval_log.set_description_str(_str)\n","            if em > best_em:\n","                best_em = em\n","            if f1 > best_f1:\n","                best_f1 = f1\n","                trainer.save(os.path.join(args.model_dir, \"best_f1_model.pt\"))\n","            if bleu > best_bleu:\n","                best_bleu = bleu\n","                trainer.save(os.path.join(args.model_dir, \"best_q_bleu_model.pt\"))\n","            if bleu_d > best_bleu_d:\n","                best_bleu_d = bleu_d\n","                trainer.save(os.path.join(args.model_dir, \"best_d_bleu_model.pt\"))\n","\n","            _str = 'BEST Q-BLEU : {:02.2f} D-BLEU : {:02.2f} EM : {:02.2f} F1 : {:02.2f}'\n","            _str = _str.format(best_bleu, best_bleu_d, best_em, best_f1)\n","            best_eval_log.set_description_str(_str)\n"],"metadata":{"id":"cmWrpSDYiYye","executionInfo":{"status":"ok","timestamp":1676467695848,"user_tz":0,"elapsed":8,"user":{"displayName":"Ayush Modi","userId":"15866713891896926467"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["main(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339,"referenced_widgets":["918f451f4e284f34a7c0389eff848ba9","8ee931e68dad40dca325201f215dbddb","3d3ebc25fccb4929ac1bb3ffa38ad32f","77222952400a41a692df2793facd3d45","9b3f851bfc1746ac892b4c9b7431564c","2fafbf663b994c89a5a1453df6a58c9a","d69164103fe34a719ceb65e9fd37a627","d7871bf7125c4fff86fdc2cd277813cf","db9c6531fc1a42a98478e42976f932ba","024ecb34e1f64d1db6be6ab6e0230b25","94f48f4dade6418695ba87558850914b","92f917ef9d85452daf5197e2b011012b","cff330c7a96b4d339cb27bbbec9a766c","ed61d11e252f458a9237e8c65261e040","8d895146260540bdb137bf4ee89f582d","c73d0068711543a6a5a88c52e292b512","d6c00cd6f90847e3a7cb5a0a8b29b54d","a109e150cb3e4c49a8c2c60aaf4d5689","bc6a3e12cfdf4fe4927cdd10ec33fdc7","7975e3420e874a3caf68fadf6ab2b6bf","e614b36f5a004cf4b3c0baa48098f62e","750aadf7f41344d2bcf29c215ad95cb7","847c6812d70047988d8facc22837e388","bfce2864f68a430fbbe4bba04d9c4650","9e996951caf046f890b32a2a51dc78b4","6dbbd329826a4c818d78f0a6b31ee97e","e1b5e507eee54bcd9eb01c0130048b19","5accf24e681d4762b07a31c63d89d503","5420ddea4ed74a20b67905593b63eddc","e134ed63a0b44968869af56741872cf8","976f8ef6a1f946d6a7972cb45e74120e","afe66292dccd4c4492fe664abaa4d56b","693af35548db4a90a6c94ba729b1b007","37ff2b3b8aa94f4b8f6bc56a8e038b99","b18c0895ac25440a942a06848998c46a","b02d68e763644e29a92894f71a09a6fd","607677972dd74e7f8e1715c8cf1d799f","fcef6eaac46a474eaad9ea000ff766f6","931cf896806943f3a30253412b913758","b29e993237fb4689844e417c4f10f433","976ec337bfde48c88b81012323f41bce","eaff55b4f17347caa12e0796e87f8b29","e9c6a15acfa44543af652cd4dff2c42b","4fbeb7ad518a409a93b2e4db1bf77233"]},"id":"aIQR4dh8niTt","outputId":"54f72117-fa81-4811-cb48-9691a0891111"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"918f451f4e284f34a7c0389eff848ba9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92f917ef9d85452daf5197e2b011012b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"847c6812d70047988d8facc22837e388"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  4.51it/s]\n","100%|██████████| 820/820 [00:13<00:00, 61.98it/s]\n","100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n","100%|██████████| 820/820 [00:12<00:00, 63.72it/s] \n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37ff2b3b8aa94f4b8f6bc56a8e038b99"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cp4tGydIYz32"},"execution_count":null,"outputs":[]}]}